"""
PrzykÅ‚ady uÅ¼ycia moduÅ‚u gesture_tracker.
Uruchom: python -m gesture_tracker.demo
"""

from simple_mpc_server.gesture_tracker.detector import GestureTracker

def example_simple():
    """Najprostszy przykÅ‚ad â€” stream z generatorem."""
    print("=== PrzykÅ‚ad 1: prosty stream ===")
    print("PokaÅ¼ dÅ‚oÅ„ do kamery. q = wyjÅ›cie")

    with GestureTracker(detect_modes=["hands"]) as tracker:
        for frame, results in tracker.stream():
            for hand in results.hands:
                status = "PIÄ˜ÅšÄ†" if hand.is_fist else f"Palce: {hand.finger_count}"
                print(f"  {status} | pozycja: ({hand.palm_center[0]:.2f}, {hand.palm_center[1]:.2f})")


def example_multi_mode():
    """Detekcja dÅ‚oni + twarzy jednoczeÅ›nie."""
    print("=== PrzykÅ‚ad 2: dÅ‚onie + twarz ===")

    with GestureTracker(detect_modes=["hands", "face"]) as tracker:
        for frame, results in tracker.stream():
            if results.hands:
                print(f"  DÅ‚onie: {len(results.hands)}")
            if results.faces:
                print(f"  Twarze: {len(results.faces)}")


def example_manual_loop():
    """PÄ™tla rÄ™czna â€” peÅ‚na kontrola."""
    print("=== PrzykÅ‚ad 3: pÄ™tla rÄ™czna ===")

    tracker = GestureTracker(detect_modes=["hands"])
    tracker.open()

    try:
        while tracker.is_opened:
            results = tracker.process_frame(draw=True)
            if results is None:
                continue

            # WÅ‚asna logika
            for hand in results.hands:
                if hand.is_fist:
                    print("PIÄ˜ÅšÄ†!")
                elif hand.finger_count == 2:
                    print("âœŒï¸ Peace!")
                elif hand.finger_count == 5:
                    print("ğŸ–ï¸ PiÄ…tka!")

            tracker.show(results.frame)
            if tracker.key_pressed("q"):
                break
    finally:
        tracker.release()


def example_no_camera():
    """Detekcja na pojedynczym obrazie (bez kamery)."""
    import cv2

    print("=== PrzykÅ‚ad 4: detekcja na zdjÄ™ciu ===")

    tracker = GestureTracker(open_camera=False)

    frame = cv2.imread("test_photo.jpg")
    if frame is None:
        print("Brak pliku test_photo.jpg, pomijam.")
        return

    results = tracker.detect(frame, modes=["hands", "face", "body"])
    print(f"  DÅ‚onie: {len(results.hands)}")
    print(f"  Twarze: {len(results.faces)}")
    print(f"  Pozy:   {len(results.poses)}")

    for i, hand in enumerate(results.hands):
        print(f"  DÅ‚oÅ„ {i}: piÄ™Å›Ä‡={hand.is_fist}, palce={hand.finger_count}")

    tracker.draw_results(results)
    cv2.imshow("Wynik", results.frame)
    cv2.waitKey(0)


def example_finger_counter():
    """Licznik palcÃ³w na Å¼ywo."""
    print("=== PrzykÅ‚ad 5: licznik palcÃ³w ===")
    print("PokaÅ¼ palce do kamery!")

    with GestureTracker() as tracker:
        for frame, results in tracker.stream():
            for hand in results.hands:
                fingers = hand.fingers_up
                names = ["Kciuk", "WskazujÄ…cy", "Åšrodkowy", "Serdeczny", "MaÅ‚y"]
                up = [n for n, f in zip(names, fingers) if f]
                print(f"  Uniesione ({hand.finger_count}): {', '.join(up) or 'Å¼aden'}")


# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    print("Wybierz przykÅ‚ad:")
    print("  1 â€” prosty stream")
    print("  2 â€” dÅ‚onie + twarz")
    print("  3 â€” pÄ™tla rÄ™czna")
    print("  4 â€” detekcja na zdjÄ™ciu")
    print("  5 â€” licznik palcÃ³w")

    choice = input("Numer: ").strip()
    examples = {
        "1": example_simple,
        "2": example_multi_mode,
        "3": example_manual_loop,
        "4": example_no_camera,
        "5": example_finger_counter,
    }

    fn = examples.get(choice)
    if fn:
        fn()
    else:
        print("Nieznany wybÃ³r, uruchamiam przykÅ‚ad 1")
        example_simple()